\section{Code Availability}
The source code for this document is available at:

\begin{center}
\fbox{\url{https://github.com/denehoffman/thesis}}
\end{center}

Additionally, all of the code used in the analysis can be found at:

\begin{center}
\fbox{\url{https://github.com/denehoffman/gluex-ksks}}
\end{center}

Running it requires some level of access to the raw GlueX data, particularly the skim of reconstructed data for this channel (mass constrained kaons with four extra RF beam bunches on either side of the in-time peak, as mentioned in the main text). The repository of code contains methods to extract these files from the Carnegie Mellon University Medium Energy Group computing cluster, although it can be modified to source local paths.

Once the files are obtained, the code executes a pipeline which outlines the various steps of the analysis described in this thesis, starting with fiducial cuts, moving to sPlot weighting, and finally performing fits over the selected, weighted data. This code is designed to be run in a container (one is provided in the repository) to ensure reproducibility of the results.

\section{The \texttt{laddu} Library}
Part of my last year of research has involved the development of a library for amplitude analysis. After using some of the available tools, I found that several experimental workflows, like the guided fits mentioned in \Cref{sub:guided-fits} and Markov-Chain Monte Carlo (MCMC) which I ended up not utilizing in this thesis, were too complex to implement within the existing frameworks. Additionally, the workflows being used to perform bootstrap analyses involved dozens of configuration files which had to be generated and modified for each individual model (multiplied by the number of bins used in binned fits). This was time-consuming and error prone, so I decided that a rewrite might give me more control over these features and a better understanding of the underlying numerical methods. The initial goal of \texttt{laddu} was to provide an interface in Python, which is great for quick prototyping and has many nicely integrated tools from other scientific libraries. At the same time, the operation needed to be as quick as possible, and I chose to write a backend in Rust. This came with several advantages and disadvantages, which I will describe in detail below. However, the outcome was a library which I enjoy using in my own projects and which I hope others find useful in their own analyses.

The major advantages of Rust are that it is mostly memory safe, meaning null pointers and a host of memory issues related to them do not exist by design. While you can still leak memory and also choose to violate memory safety if desired, the compile-time guarantee that the code will not fail at runtime, at least for these reasons, is very nice. Rust also has several well-written libraries for parallelization and Python interoperability, as well as a built in package manager, which make it easy to code and distribute a Rust-based Python library with no external dependencies.

However, a major reason why many particle physics libraries are written in C/C++ is because the ROOT library is written in those languages. There does not yet exist ROOT bindings for Rust, and methods of reading ROOT files in Rust are limited. As such, \texttt{laddu} prefers the Parquet format and provides Python-side methods for converting ROOT files into \texttt{laddu} datasets using \texttt{uproot}, a ROOT-free Python implementation of just the I/O methods required to read ROOT files.

Another disadvantage to Rust is that it is not as well-adopted by the scientific community as other languages. This will hopefully change in the future, but it is the primary reason why \texttt{laddu} was written with a Python interface in mind. However, due to the Global Interpreter Lock (GIL) present in most versions of Python\footnote{Python 3.13 now supports freethreaded builds, so this may someday be a thing of the past.}, it is currently impossible to write a model in Python which can take advantage of the parallelism built into the Rust library.

The actual structure of the library is divided into three parts, datasets, models, and evaluators. While datasets are fairly self-explanatory, models consist of sums and products of amplitudes, as well as methods which take their real and imaginary parts and their squared norms. Amplitudes, at their core, are just functions which take in an event from a dataset and output a complex value. The $Z_{\ell m}$ function from \Cref{sec:zlm} is an example of such an amplitude. \texttt{laddu} was written to spend memory over compute time, so in addition to using the data of each event, amplitudes can also cache scalars, vectors, and matrices of data which do not depend on free parameters for each event and retrieve them in their main evaluation function. In the $Z_{\ell m}$ example, the entirety of the amplitude depends only on values which are independent of any free parameters, so it is possible to cache the entire amplitude as a single complex value for every event and recall that value later. This saves time calculating expensive branches (in choosing a spherical harmonic, for example) and expensive calculations (like actually calculating said spherical harmonic), using RAM instead. The other immediate benefit of this caching is that amplitudes which appear multiple times in a model are only evaluated once. For example, the $Z_{\ell m}$ appears twice for each reflectivity, but only needs to be evaluated once per event, as the real/imaginary part can be taken from the cached value.

\texttt{laddu} organizes amplitudes into a graph structure where nodes either represent amplitudes or operations on amplitudes. While this graph does not have all the operations of a typical computer algebra system, it can be used to aid in the calculation of gradients of complex models. Since we only allow for certain operations on amplitudes, if we know the gradient of the amplitude, finding the gradient of the sum or product of several amplitudes is trivial by the chain rule. If we do not know the gradient, it can be approximated via a central finite difference, which all amplitudes use by default. However, while I was implementing the amplitudes used in this analysis, it because clear that most of them actually have a simple analytic gradient, so the implementation was straightforward. Quick calculation of gradients is very important in many optimization algorithms, including the L-BFGS-B method used in this analysis.

Another feature of \texttt{laddu} is integration with the Message Passing Interface (MPI) standard used to spread a parallel computation over multiple cores in a large computing architecture. MPI standardizes a way for each core to send and receive data from other cores, and this comes with additional benefits like being able to distribute large datasets over multiple RAM boards. It also raises any limits on the number of parallel processes to those of the available nodes in the computing framework, which can significantly speed up programs which are efficiently parallel (and \texttt{laddu} is).

As mentioned, the third part of \texttt{laddu} is the evaluators, which take a dataset or several datasets and pass them through a model to get either a projected weight which can be used to visualize a fit result or a fitting cost evaluation that can be used to minimize free parameters. The typical use of this is to construct negative log-likelihood functions from models and datasets, although the guided fit example shows that there are more complex ways to construct cost functions.

The library can be found at \url{https://github.com/denehoffman/laddu}, \url{https://pypi.org/project/laddu/}, and \url{https://crate.io/crates/laddu}.
